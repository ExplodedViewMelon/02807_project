{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle \n",
    "import networkx as nx\n",
    "from collections import deque, defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import math\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../base_graph.pkl\", 'rb') as f:\n",
    "    G_directed = pickle.load(f)\n",
    "f.close()\n",
    "G = G_directed.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"partition.pkl\", 'rb') as f:\n",
    "    partition = pickle.load(f)\n",
    "    \n",
    "with open(\"mod.pkl\", 'rb') as f:\n",
    "    mod = pickle.load(f)  \n",
    "    \n",
    "number_of_communities = len(set(partition.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "community_dict[2] = [['27c5ea64-86cb-4e69-9d13-c8ba2654515d'],\n",
    " ['2ee9a087-6188-4ebd-95b9-6561cba0584c'],\n",
    " ['efe2dd1d-706c-4ab6-bd9b-90d35a81d04f']]\n",
    "'''\n",
    "\n",
    "community_dict = {new_list: [] for new_list in range(number_of_communities)}\n",
    "for i, j in partition.items():  \n",
    "    community_dict[j].append([i])\n",
    "    \n",
    "# Filter out communities with only one element\n",
    "community_dict_bigger_than_one = {k: v for k, v in community_dict.items() if len(v) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_size = np.zeros(number_of_communities)\n",
    "\n",
    "for i,j in enumerate(community_dict):\n",
    "    community_size[i] = (len(community_dict[j]))\n",
    "    \n",
    "hist = plt.hist(community_size, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening community_text_clean.pkl\n"
     ]
    }
   ],
   "source": [
    "##    \n",
    "print('Opening community_text_clean.pkl')\n",
    "with open(\"community_text_clean.pkl\", 'rb') as f:\n",
    "    community_text_clean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening text_dict.pkl\n"
     ]
    }
   ],
   "source": [
    "## All abstracts combined for each community \n",
    "## {Community_id: <abstract1 abstract2 >,}\n",
    "## E.g: {0: <Text: structured regression has been successfully used in many...>, \n",
    "##      1: <Text: this paper considers the sparse gaussian conditional random...>,\n",
    "print('Opening text_dict.pkl')\n",
    "with open(\"text_dict.pkl\", 'rb') as f:\n",
    "    text_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = {}\n",
    "word_set = set()\n",
    "\n",
    "overall_freq = Counter()\n",
    "for i in community_text_clean:\n",
    "    try:\n",
    "        fd = nltk.FreqDist(text_dict[i])\n",
    "        word_set.update(set(list(fd.keys())))\n",
    "        overall_freq = overall_freq + Counter(fd)\n",
    "    except:\n",
    "        print('Didnt work out')\n",
    "        continue\n",
    "    TF[i] = overall_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word):\n",
    "    occ = 0\n",
    "    for i in TF:\n",
    "        com = TF.get(i)\n",
    "        if word in com.keys():\n",
    "            occ += 1\n",
    "    if occ == 0:\n",
    "        occ = 1\n",
    "    return np.log(10/occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(number, com):    \n",
    "    vec = {}\n",
    "    # Go through every word \n",
    "    for word in com.keys():\n",
    "\n",
    "        # calculate the term frequency by dividing\n",
    "        # the occurance of a certain word with the\n",
    "        # total number of words in the commnity\n",
    "        tf = TF[number][word]/len(TF[number])\n",
    "        \n",
    "        # calculates the inverse document frequency,\n",
    "        idfreq = idf(word)\n",
    "\n",
    "        # Then we multiply the two measures \n",
    "        val = tf*idfreq\n",
    "\n",
    "        # save the result in a dictionary with the word\n",
    "        # as the key and the TF-IDF score as the value\n",
    "        vec[word] = val\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_all_communities = []\n",
    "for i in TF:\n",
    "    v = tf_idf(i, TF.get(i))\n",
    "    tf_idf_all_communities.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf_idf_all_communities\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tf_idf_all_communities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "print('Opening TF.pkl')   \n",
    "with open(\"TF.pkl\", 'rb') as f:\n",
    "    TF = pickle.load(f)\n",
    " \n",
    "##    \n",
    "print('Opening TF_IDF.pkl')\n",
    "with open(\"tf_idf_all_communities.pkl\", 'rb') as f:\n",
    "    tf_idf_all_communities = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
