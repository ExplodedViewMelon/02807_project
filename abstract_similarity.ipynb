{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 6 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import mmh3\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "from dataloader import CitationDataset\n",
    "from utils import get_referenced_by, filter_df\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(nb_workers=6, progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataframe from cache /mnt/c/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/DATA/dblp-ref\n",
      "loading /mnt/c/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/DATA/dblp-ref/dblp-ref-3.json\n",
      "79007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reversing references: 100%|██████████| 79007/79007 [00:06<00:00, 12604.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79007\n",
      "Filtering dataframe...\n",
      "Initial shape: (79007, 11)\n",
      "After removing no abstract: (44970, 11)\n",
      "After removing no title: (44970, 11)\n",
      "After removing no references or citations: (33764, 11)\n",
      "33764\n"
     ]
    }
   ],
   "source": [
    "dataset = CitationDataset()\n",
    "df = dataset.load_dataframe(subset=True)\n",
    "# df.to_pickle(\"df.pkl\")\n",
    "\n",
    "# df = pd.read_pickle(\"df.pkl\")\n",
    "print(len(df))\n",
    "df = get_referenced_by(df)\n",
    "print(len(df))\n",
    "df = filter_df(df, verbose=True)\n",
    "print(len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1748950211, -1266821499, -2045041042, -2042116182, -1566184949]\n"
     ]
    }
   ],
   "source": [
    "def clean_text(aString):\n",
    "    output = aString.replace('\\n','')\n",
    "    output_list = output.split()\n",
    "    output_list = [''.join(ch for ch in aWord if ch.isalnum()) for aWord in output_list]\n",
    "    output_list = [s.lower() for s in output_list]\n",
    "    output = ' '.join(output_list)\n",
    "    return \" \".join(output.split())\n",
    "\n",
    "\n",
    "def get_signature(text: str, shingle_size = 3, sig_len = 5):\n",
    "    import sys\n",
    "    import mmh3\n",
    "    import numpy as np  \n",
    "    def shingle(text: str, shingle_size):\n",
    "        text_list = text.split()\n",
    "        return list(set(\" \".join(text_list[i:i+shingle_size]) for i in range(len(text_list)-shingle_size+1)))\n",
    "    \n",
    "    def minhash(text_list, seed) -> int:\n",
    "        hash_list = [mmh3.hash(shingle, seed) for shingle in text_list] \n",
    "        return min(hash_list)\n",
    "    \n",
    "    shingle_list = shingle(text, shingle_size)\n",
    "    if len(shingle_list) == 0:\n",
    "        return np.nan\n",
    "    try:\n",
    "        signature = [minhash(shingle_list, seed) for seed in range(sig_len)]\n",
    "    except  Exception as e:\n",
    "        print(text)\n",
    "        print(shingle_list)\n",
    "        sys.exit(e)\n",
    "    return signature\n",
    "\n",
    "\n",
    "test_string = \"this is a test string to shingle and hash\"\n",
    "print(get_signature(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a89e6d87b7e4c568056bd92c6011f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=13168), Label(value='0 / 13168')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "abstract      string[pyarrow]\n",
       "authors                object\n",
       "n_citation     int64[pyarrow]\n",
       "references             object\n",
       "title         string[pyarrow]\n",
       "venue         string[pyarrow]\n",
       "year           int64[pyarrow]\n",
       "id            string[pyarrow]\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"abstract\"] = (\n",
    "    df[\"abstract\"].parallel_apply(clean_text).convert_dtypes(dtype_backend=\"pyarrow\")\n",
    ")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0393a9ac8b354a85b62bd07ab9ecdc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=13168), Label(value='0 / 13168')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k=250\n",
    "df[\"signature\"] = df[\"abstract\"].parallel_apply(get_signature, sig_len=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,r = 50, 5\n",
    "assert k == b*r\n",
    "\n",
    "def jaccard(name1, name2, signatures_dict):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - name1 (str): key of the first document S\n",
    "        - name2 (str): key of the second document T\n",
    "        - signatures_dict (dict of str:list): dictionary of signatures\n",
    "    Return: Jaccard similarity between S and T\n",
    "    \"\"\"\n",
    "    signatures_doc1 = np.array(signatures_dict[name1])\n",
    "    signatures_doc2 = np.array(signatures_dict[name2])\n",
    "    return len(np.intersect1d(signatures_doc1, signatures_doc2))/len(np.union1d(signatures_doc1, signatures_doc2))\n",
    "\n",
    "\n",
    "def lsh(signatures_dict, jaccard_threshold=0.6, seed=42):\n",
    "    lsh_dict = {}\n",
    "    for key, values in tqdm(signatures_dict.items()):\n",
    "        blocks = np.split(np.array(values), b)\n",
    "        blocks_hash_values = []\n",
    "        for aBlock in blocks:\n",
    "            blocks_hash_values.append(mmh3.hash(aBlock, seed))\n",
    "        lsh_dict[key] = blocks_hash_values\n",
    "    list_keys = list(lsh_dict.keys())\n",
    "    similar_items = {}\n",
    "    for i in tqdm(range(len(list_keys)-1)):\n",
    "        for j in range(i+1, len(list_keys)):\n",
    "            common_values = np.intersect1d(lsh_dict[list_keys[i]], lsh_dict[list_keys[j]])\n",
    "            if len(common_values) > 0:\n",
    "                # we found a candidate\n",
    "                similarity_score = jaccard(list_keys[i], list_keys[j], signatures_dict)\n",
    "                if similarity_score >= jaccard_threshold:\n",
    "                    print(\"Found one!\")\n",
    "                    similar_items[(list_keys[i], list_keys[j])] = similarity_score\n",
    "    return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the effectiveness of a statistical machine translation system smt is very dependent upon the amount of parallel corpus used in the training phase for lowresource language pairs there are not enough parallel corpora to build an accurate smt in this paper a novel approach is presented to extract bilingual persianitalian parallel sentences from a nonparallel comparable corpus in this study english is used as the pivot language to compute the matching scores between source and target sentences and candidate selection phase additionally a new monolingual sentence similarity metric normalized google distance ngd is proposed to improve the matching process moreover some extensions of the baseline system are applied to improve the quality of extracted sentences measured with bleu experimental results show that using the new pivot based extraction can increase the quality of bilingual corpus significantly and consequently improves the performance of the persianitalian smt system\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>references</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>signature</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34231</th>\n",
       "      <td>emotional preference of people from different ...</td>\n",
       "      <td>[Atena Bajoulvand, Ramtin Zargari Marandi, Moh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[00ead8a6-882e-4ced-81b1-4e17fb95b098, 1e06b01...</td>\n",
       "      <td>Analysis of folk music preference of people fr...</td>\n",
       "      <td>Applied Mathematics and Computation</td>\n",
       "      <td>2017</td>\n",
       "      <td>3c016f11-5962-47fd-9e89-886a84a30b81</td>\n",
       "      <td>[-2140890565, -2144375480, -2123211068, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>orientations and positions of a permanent magn...</td>\n",
       "      <td>[Houde Dai, Wanan Yang, Xuke Xia, Shijian Su, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1e9afe42-b3d5-4da9-a8e6-c46b0e949b67, b8943c8...</td>\n",
       "      <td>A three-axis magnetic sensor array system for ...</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>45a7f1f0-0f69-49c3-9b76-7a9acb8a5829</td>\n",
       "      <td>[-2108729406, -2144375480, -2134336092, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52116</th>\n",
       "      <td>the popularity and reach of short text message...</td>\n",
       "      <td>[Renato Moraes Silva, Tulio C. Alberto, Tiago ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0661f7c2-6853-4e02-8e24-77a37ca7b8ab, 10bd5d8...</td>\n",
       "      <td>Towards filtering undesired short text message...</td>\n",
       "      <td>Expert Systems With Applications</td>\n",
       "      <td>2017</td>\n",
       "      <td>3505728b-8c4a-4f53-9a7e-2e639745d3c8</td>\n",
       "      <td>[-2140950911, -2144375480, -2140018415, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35045</th>\n",
       "      <td>in case of outliers it is inevitable that the ...</td>\n",
       "      <td>[Ozge Cagcag Yolcu, Hak-Keung Lam]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0575b654-767b-43e1-9d24-a096b3e5293b, 05caaba...</td>\n",
       "      <td>A combined robust fuzzy time series method for...</td>\n",
       "      <td>Neurocomputing</td>\n",
       "      <td>2017</td>\n",
       "      <td>0be8ced2-e549-4503-b212-e592f2475ed5</td>\n",
       "      <td>[-2123145952, -2144375480, -2082269033, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73470</th>\n",
       "      <td>network function virtualization nfv introduces...</td>\n",
       "      <td>[Peilong Li, Xiaoban Wu, Yongyi Ran, Yan Luo]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0ca36c27-8b86-42d5-b378-d780ea0ba5a5, 32ddb4a...</td>\n",
       "      <td>Designing Virtual Network Functions for 100 Gb...</td>\n",
       "      <td>architectures for networking and communication...</td>\n",
       "      <td>2017</td>\n",
       "      <td>86d37a89-e352-48a3-9b13-c9663330f125</td>\n",
       "      <td>[-2144845599, -2144375480, -2115858889, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>the volume of digital documents increases rapi...</td>\n",
       "      <td>[Xianghua Fu, Zhaofeng Ma, Boqin Feng]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1a7be5f4-5d85-4d5e-9ab2-67649a25eb05, 20a5606...</td>\n",
       "      <td>Kernel-Based Semantic Text Categorization for ...</td>\n",
       "      <td>grid and cooperative computing</td>\n",
       "      <td>2004</td>\n",
       "      <td>0c985c55-5d49-4e58-818d-a11d5d1ff142</td>\n",
       "      <td>[-2128616418, -2144375480, -2083914156, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29670</th>\n",
       "      <td>magnetic resonance imaging mri is widely used ...</td>\n",
       "      <td>[Mohsen Ghafoorian, Alireza Mehrtash, Tina Kap...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0dd5b8c6-c278-4a53-a9de-2dca2282c0a5, 21a6dd8...</td>\n",
       "      <td>Transfer Learning for Domain Adaptation in MRI...</td>\n",
       "      <td>arXiv: Computer Vision and Pattern Recognition</td>\n",
       "      <td>2017</td>\n",
       "      <td>ab39ca5a-622b-443f-b150-269fa8e0d581</td>\n",
       "      <td>[-2119253054, -2144375480, -2127027482, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74186</th>\n",
       "      <td>as the application of smart devices becomes mo...</td>\n",
       "      <td>[Hyeong-Jun Kim, Jin-Soo Kim]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>A user-space storage I/O framework for NVMe SS...</td>\n",
       "      <td>IEEE Transactions on Consumer Electronics</td>\n",
       "      <td>2017</td>\n",
       "      <td>ab683aea-8791-4065-80a8-f1970325a736</td>\n",
       "      <td>[-2119652966, -2144375480, -2117097154, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23151</th>\n",
       "      <td>in this study the parameter identification bas...</td>\n",
       "      <td>[Chingiz Hajiyev]</td>\n",
       "      <td>0</td>\n",
       "      <td>[5d52b7b8-a369-4b93-93ab-f19602d0c596]</td>\n",
       "      <td>Reconfigurable fault-tolerant UAV flight contr...</td>\n",
       "      <td></td>\n",
       "      <td>2016</td>\n",
       "      <td>22f16e41-ea79-4838-a569-37f5698a0450</td>\n",
       "      <td>[-2114710673, -2144375480, -2086085094, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34731</th>\n",
       "      <td>although many algorithms have been proposed no...</td>\n",
       "      <td>[Rustu Akay, Alper Basturk, Adem Kalinli, Xin ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0fa2abeb-1be2-4698-918a-86a8a0d5317d, 11685c9...</td>\n",
       "      <td>Parallel population-based algorithm portfolios...</td>\n",
       "      <td>Neurocomputing</td>\n",
       "      <td>2017</td>\n",
       "      <td>bca80292-b15b-4de0-b3e9-b6a11f439b79</td>\n",
       "      <td>[-2134139170, -2144375480, -2124030516, -21289...</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                abstract  \\\n",
       "34231  emotional preference of people from different ...   \n",
       "13277  orientations and positions of a permanent magn...   \n",
       "52116  the popularity and reach of short text message...   \n",
       "35045  in case of outliers it is inevitable that the ...   \n",
       "73470  network function virtualization nfv introduces...   \n",
       "7051   the volume of digital documents increases rapi...   \n",
       "29670  magnetic resonance imaging mri is widely used ...   \n",
       "74186  as the application of smart devices becomes mo...   \n",
       "23151  in this study the parameter identification bas...   \n",
       "34731  although many algorithms have been proposed no...   \n",
       "\n",
       "                                                 authors  n_citation  \\\n",
       "34231  [Atena Bajoulvand, Ramtin Zargari Marandi, Moh...           0   \n",
       "13277  [Houde Dai, Wanan Yang, Xuke Xia, Shijian Su, ...           0   \n",
       "52116  [Renato Moraes Silva, Tulio C. Alberto, Tiago ...           0   \n",
       "35045                 [Ozge Cagcag Yolcu, Hak-Keung Lam]           0   \n",
       "73470      [Peilong Li, Xiaoban Wu, Yongyi Ran, Yan Luo]           0   \n",
       "7051              [Xianghua Fu, Zhaofeng Ma, Boqin Feng]           0   \n",
       "29670  [Mohsen Ghafoorian, Alireza Mehrtash, Tina Kap...           0   \n",
       "74186                      [Hyeong-Jun Kim, Jin-Soo Kim]           0   \n",
       "23151                                  [Chingiz Hajiyev]           0   \n",
       "34731  [Rustu Akay, Alper Basturk, Adem Kalinli, Xin ...           0   \n",
       "\n",
       "                                              references  \\\n",
       "34231  [00ead8a6-882e-4ced-81b1-4e17fb95b098, 1e06b01...   \n",
       "13277  [1e9afe42-b3d5-4da9-a8e6-c46b0e949b67, b8943c8...   \n",
       "52116  [0661f7c2-6853-4e02-8e24-77a37ca7b8ab, 10bd5d8...   \n",
       "35045  [0575b654-767b-43e1-9d24-a096b3e5293b, 05caaba...   \n",
       "73470  [0ca36c27-8b86-42d5-b378-d780ea0ba5a5, 32ddb4a...   \n",
       "7051   [1a7be5f4-5d85-4d5e-9ab2-67649a25eb05, 20a5606...   \n",
       "29670  [0dd5b8c6-c278-4a53-a9de-2dca2282c0a5, 21a6dd8...   \n",
       "74186                                                      \n",
       "23151             [5d52b7b8-a369-4b93-93ab-f19602d0c596]   \n",
       "34731  [0fa2abeb-1be2-4698-918a-86a8a0d5317d, 11685c9...   \n",
       "\n",
       "                                                   title  \\\n",
       "34231  Analysis of folk music preference of people fr...   \n",
       "13277  A three-axis magnetic sensor array system for ...   \n",
       "52116  Towards filtering undesired short text message...   \n",
       "35045  A combined robust fuzzy time series method for...   \n",
       "73470  Designing Virtual Network Functions for 100 Gb...   \n",
       "7051   Kernel-Based Semantic Text Categorization for ...   \n",
       "29670  Transfer Learning for Domain Adaptation in MRI...   \n",
       "74186  A user-space storage I/O framework for NVMe SS...   \n",
       "23151  Reconfigurable fault-tolerant UAV flight contr...   \n",
       "34731  Parallel population-based algorithm portfolios...   \n",
       "\n",
       "                                                   venue  year  \\\n",
       "34231                Applied Mathematics and Computation  2017   \n",
       "13277                                                     2016   \n",
       "52116                   Expert Systems With Applications  2017   \n",
       "35045                                     Neurocomputing  2017   \n",
       "73470  architectures for networking and communication...  2017   \n",
       "7051                      grid and cooperative computing  2004   \n",
       "29670     arXiv: Computer Vision and Pattern Recognition  2017   \n",
       "74186          IEEE Transactions on Consumer Electronics  2017   \n",
       "23151                                                     2016   \n",
       "34731                                     Neurocomputing  2017   \n",
       "\n",
       "                                         id  \\\n",
       "34231  3c016f11-5962-47fd-9e89-886a84a30b81   \n",
       "13277  45a7f1f0-0f69-49c3-9b76-7a9acb8a5829   \n",
       "52116  3505728b-8c4a-4f53-9a7e-2e639745d3c8   \n",
       "35045  0be8ced2-e549-4503-b212-e592f2475ed5   \n",
       "73470  86d37a89-e352-48a3-9b13-c9663330f125   \n",
       "7051   0c985c55-5d49-4e58-818d-a11d5d1ff142   \n",
       "29670  ab39ca5a-622b-443f-b150-269fa8e0d581   \n",
       "74186  ab683aea-8791-4065-80a8-f1970325a736   \n",
       "23151  22f16e41-ea79-4838-a569-37f5698a0450   \n",
       "34731  bca80292-b15b-4de0-b3e9-b6a11f439b79   \n",
       "\n",
       "                                               signature       sim  \n",
       "34231  [-2140890565, -2144375480, -2123211068, -21289...  0.007905  \n",
       "13277  [-2108729406, -2144375480, -2134336092, -21289...  0.007905  \n",
       "52116  [-2140950911, -2144375480, -2140018415, -21289...  0.007905  \n",
       "35045  [-2123145952, -2144375480, -2082269033, -21289...  0.007905  \n",
       "73470  [-2144845599, -2144375480, -2115858889, -21289...  0.007905  \n",
       "7051   [-2128616418, -2144375480, -2083914156, -21289...  0.007905  \n",
       "29670  [-2119253054, -2144375480, -2127027482, -21289...  0.007905  \n",
       "74186  [-2119652966, -2144375480, -2117097154, -21289...  0.007905  \n",
       "23151  [-2114710673, -2144375480, -2086085094, -21289...  0.007905  \n",
       "34731  [-2134139170, -2144375480, -2124030516, -21289...  0.007905  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def jaccard2(signature1, signature2):\n",
    "    import numpy as np\n",
    "\n",
    "    if signature1 == np.nan or signature2 == np.nan:\n",
    "        return 0\n",
    "\n",
    "    signatures_doc1 = np.array(signature1)\n",
    "    signatures_doc2 = np.array(signature2)\n",
    "    return len(np.intersect1d(signatures_doc1, signatures_doc2)) / len(\n",
    "        np.union1d(signatures_doc1, signatures_doc2)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_most_similar(df, promt, n_top=10):\n",
    "    clean_promt = clean_text(promt)\n",
    "    promt_sig = get_signature(clean_promt)\n",
    "\n",
    "    df[\"sim\"] = df[\"signature\"].apply(jaccard2, signature2=promt_sig)\n",
    "\n",
    "    return df[df[\"sim\"] > 0].sort_values(\"sim\", ascending=False).head(n_top)\n",
    "\n",
    "\n",
    "test_idx = 500\n",
    "prompt = df.iloc[test_idx][\"abstract\"]\n",
    "# for speedup: https://stackoverflow.com/questions/73845259/efficient-cosine-similarity-between-dataframe-rows\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "df_top = get_most_similar(df.drop([test_idx], axis=0), prompt, n_top=10)\n",
    "df_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44970/44970 [00:04<00:00, 9518.78it/s] \n",
      "  0%|          | 32/44969 [00:37<14:40:01,  1.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\uroko\\OneDrive\\DTU\\tools_for_data_science\\02807_project\\abstract_similarity.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m signature_dict \u001b[39m=\u001b[39m df[df[\u001b[39m\"\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnotna()][\u001b[39m\"\u001b[39m\u001b[39msignature\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto_dict()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(lsh(signature_dict))\n",
      "\u001b[1;32mc:\\Users\\uroko\\OneDrive\\DTU\\tools_for_data_science\\02807_project\\abstract_similarity.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(list_keys)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(list_keys)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         common_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mintersect1d(lsh_dict[list_keys[i]], lsh_dict[list_keys[j]])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(common_values) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             \u001b[39m# we found a candidate\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uroko/OneDrive/DTU/tools_for_data_science/02807_project/abstract_similarity.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m             similarity_score \u001b[39m=\u001b[39m jaccard(list_keys[i], list_keys[j], signatures_dict)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mintersect1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:444\u001b[0m, in \u001b[0;36mintersect1d\u001b[1;34m(ar1, ar2, assume_unique, return_indices)\u001b[0m\n\u001b[0;32m    442\u001b[0m         ar2, ind2 \u001b[39m=\u001b[39m unique(ar2, return_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    443\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         ar1 \u001b[39m=\u001b[39m unique(ar1)\n\u001b[0;32m    445\u001b[0m         ar2 \u001b[39m=\u001b[39m unique(ar2)\n\u001b[0;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\lib\\arraysetops.py:328\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unique1d\u001b[39m(ar, return_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, return_inverse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    324\u001b[0m               return_counts\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    325\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[39m    Find the unique elements of an array, ignoring shape.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m     ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masanyarray(ar)\u001b[39m.\u001b[39;49mflatten()\n\u001b[0;32m    330\u001b[0m     optional_indices \u001b[39m=\u001b[39m return_index \u001b[39mor\u001b[39;00m return_inverse\n\u001b[0;32m    332\u001b[0m     \u001b[39mif\u001b[39;00m optional_indices:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "signature_dict = df[df[\"signature\"].notna()][\"signature\"].to_dict()\n",
    "print(lsh(signature_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
